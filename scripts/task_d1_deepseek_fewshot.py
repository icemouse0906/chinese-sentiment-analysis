"""
Task D1: DeepSeek Few-shotæƒ…æ„Ÿåˆ†ç±»
å¯¹æ¯”ä¼ ç»Ÿå¾®è°ƒæ¨¡å‹ä¸å¤§è¯­è¨€æ¨¡å‹çš„Prompt Engineeringæ•ˆæœ
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path
from openai import OpenAI
from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix
import json
from datetime import datetime
from tqdm import tqdm
import time

class DeepSeekClassifier:
    """DeepSeekæƒ…æ„Ÿåˆ†ç±»å™¨"""
    
    def __init__(self, api_key=None, base_url="https://api.deepseek.com"):
        """
        åˆå§‹åŒ–DeepSeekå®¢æˆ·ç«¯
        
        Args:
            api_key: DeepSeek APIå¯†é’¥ï¼ˆå¦‚æœªæä¾›åˆ™ä»ç¯å¢ƒå˜é‡è¯»å–ï¼‰
            base_url: APIåœ°å€
        """
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        if not self.api_key:
            raise ValueError("è¯·è®¾ç½®DEEPSEEK_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")
        
        self.client = OpenAI(
            api_key=self.api_key,
            base_url=base_url
        )
        self.model = "deepseek-chat"
    
    def create_few_shot_prompt(self, examples, test_text, task_type="sentiment"):
        """
        åˆ›å»ºFew-shotæç¤ºè¯
        
        Args:
            examples: ç¤ºä¾‹åˆ—è¡¨ [(text, label), ...]
            test_text: å¾…åˆ†ç±»æ–‡æœ¬
            task_type: ä»»åŠ¡ç±»å‹ï¼ˆsentiment/absaï¼‰
        """
        if task_type == "sentiment":
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸­æ–‡æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚è¯·æ ¹æ®ç»™å®šçš„è¯„è®ºæ–‡æœ¬ï¼Œåˆ¤æ–­å…¶æƒ…æ„Ÿå€¾å‘ã€‚
è¾“å‡ºæ ¼å¼ï¼šä»…è¾“å‡º"æ­£é¢"æˆ–"è´Ÿé¢"ï¼Œä¸è¦æœ‰ä»»ä½•é¢å¤–è§£é‡Šã€‚"""
            
            user_prompt = "ä»¥ä¸‹æ˜¯ä¸€äº›ç¤ºä¾‹ï¼š\n\n"
            for text, label in examples:
                label_text = "æ­£é¢" if label == 1 else "è´Ÿé¢"
                user_prompt += f"è¯„è®ºï¼š{text}\næƒ…æ„Ÿï¼š{label_text}\n\n"
            
            user_prompt += f"ç°åœ¨è¯·åˆ¤æ–­ä»¥ä¸‹è¯„è®ºçš„æƒ…æ„Ÿï¼š\nè¯„è®ºï¼š{test_text}\næƒ…æ„Ÿï¼š"
            
        elif task_type == "absa":
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–¹é¢çº§æƒ…æ„Ÿåˆ†æï¼ˆABSAï¼‰åŠ©æ‰‹ã€‚è¯·ä»è¯„è®ºä¸­æå–ï¼ˆæ–¹é¢è¯ï¼Œè§‚ç‚¹è¯ï¼Œæƒ…æ„Ÿææ€§ï¼‰ä¸‰å…ƒç»„ã€‚
è¾“å‡ºæ ¼å¼ï¼šJSONæ•°ç»„ï¼Œä¾‹å¦‚ï¼š[{"aspect": "æœåŠ¡", "opinion": "æ€åº¦å¥½", "sentiment": "æ­£é¢"}]"""
            
            user_prompt = f"è¯·åˆ†æä»¥ä¸‹è¯„è®ºçš„æ–¹é¢çº§æƒ…æ„Ÿï¼š\n{test_text}"
        
        return system_prompt, user_prompt
    
    def classify_sentiment(self, text, examples=None, max_retries=3):
        """
        æƒ…æ„Ÿåˆ†ç±»
        
        Args:
            text: å¾…åˆ†ç±»æ–‡æœ¬
            examples: Few-shotç¤ºä¾‹
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        """
        if examples is None:
            # Zero-shoté»˜è®¤ç¤ºä¾‹
            examples = []
        
        system_prompt, user_prompt = self.create_few_shot_prompt(examples, text, "sentiment")
        
        for attempt in range(max_retries):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    temperature=0.1,  # ä½æ¸©åº¦ä¿è¯ç¨³å®šè¾“å‡º
                    max_tokens=10
                )
                
                result = response.choices[0].message.content.strip()
                
                # è§£æç»“æœ
                if "æ­£é¢" in result:
                    return 1, result
                elif "è´Ÿé¢" in result:
                    return 0, result
                else:
                    # å¦‚æœè¾“å‡ºä¸æ˜ç¡®ï¼Œä½¿ç”¨æ›´ä¸¥æ ¼çš„åŒ¹é…
                    if "positive" in result.lower() or "å¥½" in result:
                        return 1, result
                    elif "negative" in result.lower() or "å·®" in result:
                        return 0, result
                    else:
                        # é‡è¯•
                        if attempt < max_retries - 1:
                            time.sleep(1)
                            continue
                        else:
                            return -1, result  # æ— æ³•åˆ¤æ–­
            
            except Exception as e:
                print(f"  âš ï¸  APIè°ƒç”¨å¤±è´¥ (å°è¯• {attempt+1}/{max_retries}): {str(e)}")
                if attempt < max_retries - 1:
                    time.sleep(2)
                else:
                    return -1, str(e)
        
        return -1, "æœªçŸ¥"
    
    def extract_absa_triplets(self, text):
        """æå–ABSAä¸‰å…ƒç»„"""
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–¹é¢çº§æƒ…æ„Ÿåˆ†æåŠ©æ‰‹ã€‚è¯·ä»è¯„è®ºä¸­æå–ï¼ˆæ–¹é¢è¯ï¼Œè§‚ç‚¹è¯ï¼Œæƒ…æ„Ÿææ€§ï¼‰ä¸‰å…ƒç»„ã€‚
è¾“å‡ºæ ¼å¼ï¼šJSONæ•°ç»„ï¼Œä¾‹å¦‚ï¼š[{"aspect": "æœåŠ¡", "opinion": "æ€åº¦å¥½", "sentiment": "æ­£é¢"}]
å¦‚æœæ²¡æœ‰æ˜ç¡®çš„æ–¹é¢è¯ï¼Œè¯·æå–"æ•´ä½“"ä½œä¸ºæ–¹é¢è¯ã€‚"""
        
        user_prompt = f"è¯·åˆ†æä»¥ä¸‹è¯„è®ºçš„æ–¹é¢çº§æƒ…æ„Ÿï¼š\n{text}"
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=500
            )
            
            result = response.choices[0].message.content.strip()
            
            # å°è¯•è§£æJSON
            try:
                triplets = json.loads(result)
                return triplets, result
            except:
                # å¦‚æœä¸æ˜¯æ ‡å‡†JSONï¼Œè¿”å›åŸå§‹æ–‡æœ¬
                return [], result
        
        except Exception as e:
            print(f"  âš ï¸  ABSAæå–å¤±è´¥: {str(e)}")
            return [], str(e)

def load_test_data(dataset_name, sample_size=100):
    """åŠ è½½æµ‹è¯•æ•°æ®"""
    base_dir = Path(__file__).parent.parent
    
    if dataset_name == 'chnsenticorp':
        data_path = base_dir / 'NLPæ•°æ®é›†/é…’åº—è¯„è®ºæ•°æ®/ChnSentiCorp_htl_all.csv'
    elif dataset_name == 'waimai10k':
        data_path = base_dir / 'NLPæ•°æ®é›†/å¤–å–è¯„è®ºæ•°æ®/waimai_10k.csv'
    else:
        raise ValueError(f"æœªçŸ¥æ•°æ®é›†: {dataset_name}")
    
    df = pd.read_csv(data_path)
    
    # éšæœºé‡‡æ ·ï¼ˆä¿æŒç±»åˆ«å¹³è¡¡ï¼‰
    df_sampled = df.groupby('label', group_keys=False).apply(
        lambda x: x.sample(min(len(x), sample_size // 2), random_state=42)
    )
    
    return df_sampled

def evaluate_deepseek(dataset_name, shot_type='zero-shot', n_examples=5, sample_size=100):
    """
    è¯„ä¼°DeepSeekæ¨¡å‹æ€§èƒ½
    
    Args:
        dataset_name: æ•°æ®é›†åç§°
        shot_type: 'zero-shot' æˆ– 'few-shot'
        n_examples: Few-shotç¤ºä¾‹æ•°é‡
        sample_size: æµ‹è¯•æ ·æœ¬æ•°é‡
    """
    print(f"\n{'='*70}")
    print(f"DeepSeek {shot_type.upper()} æƒ…æ„Ÿåˆ†ç±»è¯„ä¼°".center(70))
    print(f"æ•°æ®é›†: {dataset_name} | æµ‹è¯•æ ·æœ¬: {sample_size}".center(70))
    print(f"{'='*70}\n")
    
    # åŠ è½½æ•°æ®
    print("ğŸ“Š åŠ è½½æµ‹è¯•æ•°æ®...")
    df = load_test_data(dataset_name, sample_size)
    print(f"   æµ‹è¯•é›†å¤§å°: {len(df)} æ¡")
    print(f"   æ­£è´Ÿæ ·æœ¬: {(df['label']==1).sum()} / {(df['label']==0).sum()}")
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    print("\nğŸš€ åˆå§‹åŒ–DeepSeekåˆ†ç±»å™¨...")
    try:
        classifier = DeepSeekClassifier()
        print("   âœ… è¿æ¥æˆåŠŸ")
    except Exception as e:
        print(f"   âŒ åˆå§‹åŒ–å¤±è´¥: {str(e)}")
        print("\nğŸ’¡ æç¤ºï¼šè¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
        print("   export DEEPSEEK_API_KEY='your-api-key'")
        return
    
    # å‡†å¤‡Few-shotç¤ºä¾‹
    examples = []
    if shot_type == 'few-shot':
        print(f"\nğŸ“ å‡†å¤‡ {n_examples} ä¸ªFew-shotç¤ºä¾‹...")
        # ä»æ•°æ®é›†ä¸­é€‰æ‹©ç¤ºä¾‹ï¼ˆä¸ä¸æµ‹è¯•é›†é‡å ï¼‰
        all_data = pd.read_csv(Path(__file__).parent.parent / f'NLPæ•°æ®é›†/{"é…’åº—è¯„è®ºæ•°æ®" if dataset_name == "chnsenticorp" else "å¤–å–è¯„è®ºæ•°æ®"}/{"ChnSentiCorp_htl_all.csv" if dataset_name == "chnsenticorp" else "waimai_10k.csv"}')
        example_indices = df.index.tolist()
        remaining_data = all_data[~all_data.index.isin(example_indices)]
        
        # å‡è¡¡é€‰æ‹©æ­£è´Ÿæ ·æœ¬
        pos_examples = remaining_data[remaining_data['label'] == 1].sample(n_examples // 2, random_state=42)
        neg_examples = remaining_data[remaining_data['label'] == 0].sample(n_examples // 2, random_state=42)
        
        for _, row in pd.concat([pos_examples, neg_examples]).iterrows():
            examples.append((row['review'][:100], row['label']))  # é™åˆ¶é•¿åº¦
        
        print(f"   ç¤ºä¾‹æ ·æœ¬:")
        for text, label in examples[:2]:
            print(f"   - [{label}] {text[:50]}...")
    
    # æ‰¹é‡é¢„æµ‹
    print(f"\nğŸ”® å¼€å§‹é¢„æµ‹...")
    predictions = []
    raw_outputs = []
    
    for idx, row in tqdm(df.iterrows(), total=len(df), desc="   é¢„æµ‹è¿›åº¦"):
        pred, output = classifier.classify_sentiment(row['review'], examples)
        predictions.append(pred)
        raw_outputs.append(output)
        
        # é™é€Ÿï¼ˆé¿å…APIé™æµï¼‰
        time.sleep(0.5)
    
    # è¿‡æ»¤æ— æ•ˆé¢„æµ‹
    valid_mask = np.array(predictions) != -1
    df_valid = df[valid_mask].copy()
    predictions_valid = np.array(predictions)[valid_mask]
    
    print(f"\n   æœ‰æ•ˆé¢„æµ‹: {len(predictions_valid)} / {len(predictions)}")
    
    if len(predictions_valid) == 0:
        print("âŒ æ— æœ‰æ•ˆé¢„æµ‹ï¼Œè¯„ä¼°ç»ˆæ­¢")
        return
    
    # è®¡ç®—æŒ‡æ ‡
    y_true = df_valid['label'].values
    y_pred = predictions_valid
    
    accuracy = accuracy_score(y_true, y_pred)
    f1_macro = f1_score(y_true, y_pred, average='macro')
    f1_weighted = f1_score(y_true, y_pred, average='weighted')
    
    print(f"\n{'='*70}")
    print("ğŸ“Š è¯„ä¼°ç»“æœ".center(70))
    print(f"{'='*70}")
    print(f"å‡†ç¡®ç‡ (Accuracy):    {accuracy:.4f}")
    print(f"å®F1 (Macro F1):      {f1_macro:.4f}")
    print(f"åŠ æƒF1 (Weighted F1): {f1_weighted:.4f}")
    
    # åˆ†ç±»æŠ¥å‘Š
    report = classification_report(y_true, y_pred, target_names=['è´Ÿé¢', 'æ­£é¢'], output_dict=True)
    report_df = pd.DataFrame(report).T
    
    print(f"\nè¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
    print(report_df.to_string())
    
    # ä¿å­˜ç»“æœ
    output_dir = Path(__file__).parent.parent / 'results' / 'deepseek' / dataset_name / shot_type
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜åˆ†ç±»æŠ¥å‘Š
    report_df.to_csv(output_dir / 'classification_report.csv')
    
    # ä¿å­˜é¢„æµ‹ç»“æœ
    results_df = df_valid.copy()
    results_df['prediction'] = predictions_valid
    results_df['raw_output'] = [raw_outputs[i] for i in range(len(raw_outputs)) if valid_mask[i]]
    results_df.to_csv(output_dir / 'predictions.csv', index=False)
    
    # ä¿å­˜æ±‡æ€»
    summary = {
        'dataset': dataset_name,
        'shot_type': shot_type,
        'n_examples': n_examples if shot_type == 'few-shot' else 0,
        'test_size': len(df_valid),
        'accuracy': float(accuracy),
        'f1_macro': float(f1_macro),
        'f1_weighted': float(f1_weighted),
        'timestamp': datetime.now().isoformat()
    }
    
    with open(output_dir / 'summary.json', 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_dir}")
    print(f"{'='*70}\n")
    
    return summary

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='DeepSeek Few-shotæƒ…æ„Ÿåˆ†ç±»')
    parser.add_argument('--dataset', type=str, default='chnsenticorp',
                        choices=['chnsenticorp', 'waimai10k'],
                        help='æ•°æ®é›†åç§°')
    parser.add_argument('--shot-type', type=str, default='zero-shot',
                        choices=['zero-shot', 'few-shot'],
                        help='Shotç±»å‹')
    parser.add_argument('--n-examples', type=int, default=5,
                        help='Few-shotç¤ºä¾‹æ•°é‡')
    parser.add_argument('--sample-size', type=int, default=100,
                        help='æµ‹è¯•æ ·æœ¬æ•°é‡')
    
    args = parser.parse_args()
    
    try:
        summary = evaluate_deepseek(
            args.dataset,
            args.shot_type,
            args.n_examples,
            args.sample_size
        )
        
        if summary:
            print("ğŸ‰ è¯„ä¼°å®Œæˆ!")
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        exit(1)

if __name__ == '__main__':
    main()
